<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>ScPoEconometrics</title>
    <meta charset="utf-8" />
    <meta name="author" content="Florian Oswald, Gustave Kenedi and Pierre Villedieu" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <script src="https://use.fontawesome.com/5235085b15.js"></script>
    <link rel="stylesheet" href="..\css\scpo.css" type="text/css" />
    <link rel="stylesheet" href="..\css\scpo-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# ScPoEconometrics
## Intro To Causality
### Florian Oswald, Gustave Kenedi and Pierre Villedieu
### SciencesPo Paris </br> 2020-03-02

---


layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---



layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---

# Recap from last week

* Simple Linear Regression model: `\(\widehat y_i = b_0 + b_1 x_i\)`

* Ordinary Least Squares (OLS) estimation: minimize the sum of squared errors

* R command to estimate a linear model: `lm(dependent variable ~ independent variable, data)`


## Today - Introduction to causal inference

* Causality versus correlation

* The Potential Outcome Framework a.k.a. Rubin's Causal Model

* Randomized controlled trials (RCTs)

* Follow up on the empirical application of *class size* and *student performance*

---

# Why do we care about causality?

Many of the *interesting questions* we might want to answer with data are causal

--

- **Understanding** the world

  - Social sciences : Why people behave in the way they do? 
  - Health sciences : Why people get sick? How to cure them?

--

- Causal understanding is also of first interest for **public planers**

  - How to reduce unemployment? You need to know what cause unemployment... 
  - Should governments care about the level of public debt? 

--

- Note that some questions we might want to answer are non causal 
  - Most *Artificial Intelligence* tasks only care about **prediction**
  - Ex : "how can we predict whether a photo is of a dog or a cat" is vital to how Google Images works, but it doesn't care what *caused* the photo to be of a dog or a cat.

---

# Causality and Economics

- Making causal inference from data can be seen as the economists' comparative advantage among social sciences!

- Plenty of fields do statistics. But very few make it standard training for their students to understand causality.

- The care of economists for making consistent causal inference is also what makes them useful both in private (tech companies for example) or public sector (policy advisors) 

--

- Ok, that's enough lobbying... üòÖ


---

# The Concept of Causality

Causality : what are we talking about? 

- We say that `X` *causes* `Y`...

--

  - if we were to intervene and *change* the value of `X` without changing anything else...
    
--

  - then `Y` would also change as a result

- The key point here is the *without changing anything else*, often refered as the **Ceteris Paribus assumption**

--

- ‚ö†Ô∏è It does **NOT** mean that `X` is the only factor only that causes `Y`

---

# Correlation vs Causation

* That's becomes almost a trueism: *Correlation is not equal Causation*.

* Well, we're here to figure out conditions when it **is**!

* Econometrics is about stating the conditions under which we can claim that a relationship is causal.

---

# Some funny correlations...

... that are obviously not causation 

You can have a look to the [Spurious correlation website](https://www.tylervigen.com/spurious-correlations)

.pull-left[
![:scale 90%](../img/photos/spurious.png)
]

.pull-right[
- Who would believe that sociologist can help into space lauching? üòÑ
]


But not all correlations are so easy to rule out

---

# Correlation vs. causality : smoking and lung cancer #1

**Does smoking cause lung cancer?** 

- Today, we know the answer and it is YES! 

.pull-left[
- But let's go back in the 1950's

  - We are at the start of a big increase in deaths from lung cancer...
  
  - ... which is happening after a fast growth of cigarette consumption
]

--

.pull-right[
![:scale 75%](../img/photos/Smoking_lung_cancer.png)
]

--
- Again, it is very temptative to claim that smoking does cause lung cancer based on this graph.

---

# Correlation vs. causality : smoking and lung cancer #1

.pull-left[
![:scale 90%](../img/photos/Smoking_lung_cancer.png)
]

.pull-right[

At the time many people were still skeptical, including some famous statisticians :

1) Other macro factors have also changed between 1900 and 1950

  - Tarring of roads

  - Inhalation of motor exhausts (leaded gasoline fumes)

  - General greater air pollution.

]

---

# Correlation vs. causality : smoking and lung cancer #1

.pull-left[
![:scale 90%](../img/photos/Smoking_lung_cancer.png)
]

.pull-right[

At the time many people were still skeptical, including some famous statisticians :

2) **Self selection problem** : Smokers and non smokers may be different in the first place 
  
  - Selection on observables characteristics : age, education, income, ...
  
  - Selection on unobservables : the hypothetical confounding genome theory of Fisher. 

]

---

# Correlation vs. causality : smoking and lung cancer #2

- Let's focus on one of these potential confounding characteristics : **age**.

- Based on [(Cochran 1968)](https://www.jstor.org/stable/2528036?origin=crossref&amp;seq=11#metadata_info_tab_contents), we will use death rates from lung cancer in Canada, U.K. and U.S.. 

.pull-left[
Death rates per 1,000 person-years

![:scale 80%](../img/photos/raw_death_rates.png)

]

--

.pull-right[
&lt;/br&gt;

- We are 30% (U.S.) to 75% (Canada) more likely to find death from lung cancer among cigar/pipe smokers than non-smokers.

]

--

.pull-left[
* But, the age distribution vary a lot accross groups
]

.pull-right[
![:scale 60%](../img/photos/age_by_smoking_status.png)
]

---

class:inverse

# Correlation vs. causality : smoking and lung cancer #3

Let's adjust our statistics taking into account the age distribution of pipe-smokers.

![:scale 40%](../img/photos/ex_cigar_subclassif.png)


This table gives a 3 age group distribution of 40 pipe-smokers and 40 non-smokers, as well as the death rate of pipe-smokers for each age group.

**Questions** 

- What is the average death rate for pipe smokers?

- What would the average mortality rate be for pipe smokers if they had the same age distribution as the non-smokers?

---


# Correlation vs. causality : smoking and lung cancer #4

Here is the adjusted death rates table found by [(Cochran 1968)](https://www.jstor.org/stable/2528036?origin=crossref&amp;seq=11#metadata_info_tab_contents) using 3 age groups

![:scale 40%](../img/photos/adjusted_death_rates.png)

- Cigars/pipes seem much less dangerous than in the previous table...

- ... but this table still does not allow us to tell about the causal effect of smoking. 

- There are still a lot of **confounding factors** that we are not controling for. 

---

# How Can We Tell?

- Sometimes correlations are just pure artefacts : there is no causal relationship between the variables of interest

- In some other cases, there are both correlation and causality but not of the same **magnitude**, or even the same **direction**.

--

- So how can we make causal inference then ? 

- The **Potential Outcomes framework** will be helpful to find out.



---
layout: false
class: title-slide-section-red, middle

# Causal Inference

---
layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---

# The Potential Outcomes Model of causal inference

Often called the **Rubin Causal Model** in memory of the statistician **Donald Rubin** who generalised and formalized this model in the 1970's.&lt;sup&gt;1&lt;sup/&gt;

--

* **Key idea/assumption** : Each individual can be exposed to **multiple alternative states of a cause**, i.e. two treatment state.
For example :
  - smoking or non-smoking 
  - growing up in a poor vs a rich neighborhood
  - being in a small or a big class 
  
--

.pull-left[
* Let this treatment be a binary variable

For example : 
$$
D_i = \begin{cases} 
                    1 \textrm{ if i in a small class} \\\\ 
                    0 \textrm{ if i in a big class} 
      \end{cases}
$$
]

--

.pull-right[

* For each `\(i\)`, we **observe** the value of `\(D_i\)`. 

* In real life, `\(D_i\)` is either equal to 0 or 1. 
]

.footnote[
[1]: The potential outcomes framework was first proposed by Jerzy Neyman in his 1923 Master's thesis.
]

---


# The Potential Outcomes Model of causal inference

* In this framework, each individual has two potential outcomes 

$$
\textrm{Potential outcome} = \begin{cases} 
                    Y_i^1 \textrm{  if } D_i = 1 \\\\ 
                    Y_i^0 \textrm{  if } D_i = 0 
      \end{cases}
$$
* It allows us to define the **individual treatment effect**

$$ \delta_i = Y_i^1 - Y_i^0$$
* N.b. : `\(\delta_i\)` measures the **causal effect of `\(D\)`** for the individual `\(i\)` on the outcome `\(Y\)`
* Problem : We only observe one of both potential outcomes, so we cannot compute `\(\delta_i\)` for any `\(i\)`. This is know as the **fundamental problem of causal inference**. 

* The potential outcome that is not observed exists in principle, it is called the **counterfactual outcome**.

  * What your test score would have been if you have been in a big class, knowing that you were in a small one.


---

# The Potential Outcomes Model

We may also (mostly) be interested in average effect in the population, in particular :


* The **A**verage **T**reatment **E**ffect

`\begin{align}
ATE &amp;= \mathop{\mathbb{E}}(\delta_i) \\
    &amp;= \mathop{\mathbb{E}}(Y_i^1 - Y_i^0) \\ 
    &amp;= \mathop{\mathbb{E}}(Y_i^1) - \mathop{\mathbb{E}}(Y_i^0)
\end{align}`
  
* The ATE simply measures the **average of individual treatment effects over the whole population**. 
  
  * The `\(\mathop{\mathbb{E}}(.)\)` symbol stands for *expectation* or *population mean*

---

# The Potential Outcomes Model

We may also (mostly) be interested in average effect in the population, in particular :

* The **A**verage **T**reatment Effect on the **T**reated

`\begin{align}
 ATT &amp;= \mathop{\mathbb{E}}(\delta_i | D_i = 1) \\
     &amp;= \mathop{\mathbb{E}}(Y_i^1 - Y_i^0 | D_i = 1) \\
     &amp;= \mathop{\mathbb{E}}(Y_i^1 | D_i = 1) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 1)
\end{align}`

* The ATT measures the **average treatment effect conditional on being a treatment group member**, all `\(i\)` such that `\(D_i = 1\)`

  * The `\(\mathop{\mathbb{E}}(Y_i|D_i=1)\)` symbol stands for *conditional expectation*. It refers to the expectation over a subcategory of the entire population, namely people who satisfy the condition `\(D_i = 1\)`.

* In the same way we can define the **A**verage **T**reatment Effect on the **U**treated as : 

`\begin{align}
 ATU &amp;= \mathop{\mathbb{E}}(\delta_i | D_i = 0)
\end{align}`

---

# Facing the problem of causal inference #1

* We have the same **missing data problem** for computing ATE, ATT or ATU than for `\(\delta_i\)`. Either `\(Y_i^1\)` or `\(Y_i^0\)` is missing for each `\(i\)`. 

--

* There is a simple estimator that can be computed from the data we have :

$$ \mathop{\mathbb{E}}(Y_i^1|D_i=1) - \mathop{\mathbb{E}}(Y_i^0|D_i=0) $$ 

* We simply **difference the mean outcomes in both treatment groups**. For example, it would consist in taking the difference between :
  * Death rates for smokers and non-smokers 
  * GDP growth for democratic and non democratic countries
  * Unemployment rates for countries with and without a minimum wage

* Most of the time, such an estimate **will fail to the capture causal effect** of the treatment

* Notice that this kind raw comparison is often done by journalists / politicians / ... 

---

# Facing the problem of causal inference #2

Let's decompose the simple difference in mean ouctomes. 

`\begin{align}
  \mathop{\mathbb{E}}(Y_i^1|D_i=1) - \mathop{\mathbb{E}}(Y_i^0|D_i=0) &amp;= \mathop{\mathbb{E}}(Y_i^0 + \delta_i | D_i = 1) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 0)
\end{align}`

For simplicity, suppose **treatment effect is constant** across people : `\(\forall i : \delta_i = \delta\)`

Then,

`\begin{align}
  \mathop{\mathbb{E}}(Y_i^1|D_i=1) - \mathop{\mathbb{E}}(Y_i^0|D_i=0) &amp;= \delta + \mathop{\mathbb{E}}(Y_i^0 | D_i = 1) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 0)
\end{align}`

And because `\(ATE = \mathop{\mathbb{E}}(\delta_i) \underbrace{=}_\text{constant treatment effect} \mathop{\mathbb{E}}(\delta) = \delta\)` we have : 


`\begin{align}
  \mathop{\mathbb{E}}(Y_i^1|D_i=1) - \mathop{\mathbb{E}}(Y_i^0|D_i=0) &amp;= ATE + \underbrace{\mathop{\mathbb{E}}(Y_i^0 | D_i = 1) - \mathop{\mathbb{E}}(Y_i^0 | D_i = 0)}_\text{Selection bias}
\end{align}`

---

class:inverse

# Facing the problem of causal inference #3

###**Task**

Let's compute the selection bias with some toy data 


---

layout: false
class: title-slide-section-red, middle

# Experiments

---
layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---

# Experiments

- A common way to do this in many fields is an *experiment*, Often called **R**andom **C**ontrolled **T**rial (RCT).

- If you can *randomly assign* `D`, then you know that the people with `D=0` are, on average, exactly the same as the people with `D=1`.

- So simple comparisons will allow you to make causal inference!


---

# Back to class size and students' achievements

In past session we regress some average student standardized score on class size. 

`$$\textrm{test_score}_i = b_0 + b_1 \textrm{class_size}_i + e_i$$`
We briefly discuss why `\(b_1^{OLS}\)` may not be measuring the causal effect of class size on students' test scores? 

--

* **Students sorting** : There is selection into schools with different sized classes. Suppose parents have a prior that smaller classes are better - they will try to get their kids into those schools.

--

* **Teachers sorting** : teachers could sort towards schools with smaller classes because it‚Äôs easier to teach a small rather than a large class, and if there is competition for those places and higher quality teachers will have an advantage.

---

# The STAR Experiment #1
Tennessee **S**tudent/**T**eacher **A**chievement **R**atio Experiment

* The experiment started in 1985-1986 and lasting for four years

* 11,600 students and their teachers where **randomly assigned** to to one of the following three groups:

  1. **Small class** of 13-17 students
  2. **Regular class** of 22-25 students
  3. **Regular class** of 22-25 students with a full-time teacher's **aide**

* Students to remain in the same class type for four years

* Randomization occurred within schools.

---

class:inverse


# The STAR Experiment #2

**Task 2** 

1) Load the *STAR* data from this [link]() and assign it to an object called `star_df`. 

```
##   gender ethnicity  birth grade    star read math    lunch   school   degree ladder experience tethnicity system
## 1 female      afam 1979.5     k    &lt;NA&gt;   NA   NA     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         NA       &lt;NA&gt;     NA
## 2 female      afam 1979.5     1    &lt;NA&gt;   NA   NA     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         NA       &lt;NA&gt;     NA
## 3 female      afam 1979.5     2    &lt;NA&gt;   NA   NA     &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;   &lt;NA&gt;         NA       &lt;NA&gt;     NA
## 4 female      afam 1979.5     3 regular  580  564     free suburban bachelor level1         30       cauc     22
## 5 female      cauc   1980     k   small  447  473 non-free    rural bachelor level1          7       cauc     30
## 6 female      cauc   1980     1   small  507  538     free    rural bachelor level1          7       cauc     30
##   schoolid
## 1       NA
## 2       NA
## 3       NA
## 4       54
## 5       63
## 6       63
```
2) What's the unit of observation? What's the meaning of NA's here? Meaning of variables

3) Balancing checks 

---

class:inverse

# The STAR Experiment #2

**Task 2** 

Let's first focus on small size vs regular class (without aide)

We take the fact of being in small class has being treated, i.e. `\(D_i = 1\)` if `\(i\)` in a small class.

3) How would you get an estimate of the ATE for kindergarden grade (`k`)? Compute it for both math and reading score. 



4) Compute the ATE for every grades. 



5) Produce a bar plot to vizualize the difference in the ATE betwwen grades and test. 



---

# Implementing STAR #3 

Comparing the achievments between each group using **regression**

The model we estimate is : `\(Y_{i} = b_0 + b_1\textrm{SMALL}_{i} + b_2 \textrm{REG&amp;A}_{i} + e_i\)`

.pull-left[

]

--

.pull-right[

* Based on these results, would you advise to reduce class size or provide additional teaching aide? 

* What is the value of `\(b_1\)` for grade3? Interpret this value.

* What are the limits of such an experiment? 

]
---

# Pros and cons of RCT's 

RCTs are often seen as the **gold standard of causal inference**

* The Nobel price in economics has recently (2019) been awarded to three exponents of the RCT literature, [Duflo, Banerje and Kremer](https://www.economist.com/finance-and-economics/2019/10/17/a-nobel-economics-prize-goes-to-pioneers-in-understanding-poverty).

* The main strenght of RCTs is their **internal validity** : we are very confident that the estimates we get are capturing causal effects 

--

But it has also several shortcomings 

* **External validity issue**: How much can we generalize from given RCT's results? 
* RCTs are **costly** both in time and money
* RCTs may face some **ethical issues** : there is some treatment that cannot be assigned to people 

* ...

---


# Back to model 

* If we cannot run an RCT (most of the time) we have to find way to make causal inference from **observational data**

* It brings us back to models 

- In causal inference, the *model* is our idea of what we think the process is that *generated the data*.

- We have to make some assumptions about what this is!

- We put together what we know about the world with assumptions and end up with our model.

- The model can then tell us what kinds of things could give us wrong results so we can fix them and get the right counterfactual.

---

# Models

- Wouldn't it be nice to not have to make assumptions?

- Yeah, but it's impossible to skip!

- We're trying to predict something tat hasn't happened - a counterfactual.

- This is literally impossible to do if you don't have some model of how the data is generated.

- You can't even predict the sun will rise tomorrow without a model!

- If you think you can, you're just don't realize the model you're using - that's dangerous!

---

# Teaser of next sessions 

The approach taken to make causal inference will depend on the 

---


# An Example: Randomization

- Let's generate some data.
- Let's say that getting `X` causes `Y` to increase by 100.
- And let's run a randomized experiment of who actually gets X and estimate the size of the effect (should be close to `100`!)

.pull-left[

```r
true_effect &lt;- 100
df &lt;- tibble(Y.without.X = rnorm(1000),
             X=sample(c(0,1),1000,replace=T)) %&gt;%
  mutate(Y.with.X = Y.without.X + true_effect) %&gt;%
  #Now assign who actually gets X
  mutate(Observed.Y = ifelse(X==1,Y.with.X,Y.without.X))
head(df,4)
```

```
## # A tibble: 4 x 4
##   Y.without.X     X Y.with.X Observed.Y
##         &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;
## 1       1.07      0     101.      1.07 
## 2       0.368     1     100.    100.   
## 3       1.53      0     102.      1.53 
## 4       0.619     0     101.      0.619
```
]

.pull-right[
* Now, estimate the group means and simply difference them:

```r
#And see what effect our experiment suggests X has on Y
df %&gt;% group_by(X) %&gt;% 
  summarize(Y = mean(Observed.Y)) %&gt;%
  pull(Y) %&gt;% diff
```

```
## [1] 100.0057
```
]

* That's pretty close to the true effect there!

---

# An Example: No Randomization

- Suppose now we can *not* randomize the `X`.

- Instead there is some kind of rule that decides about `X`.

.pull-left[

```r
df &lt;- tibble(Z = runif(10000)) %&gt;% 
  mutate(Y.without.X = rnorm(10000)+100*Z, 
         Y.with.X = Y.without.X + 100) %&gt;%
  #Now assign who actually gets X
  mutate(X = Z &gt; .9,
         Observed.Y = ifelse(X==1,Y.with.X,Y.without.X))
head(df)
```

```
## # A tibble: 6 x 5
##        Z Y.without.X Y.with.X X     Observed.Y
##    &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;lgl&gt;      &lt;dbl&gt;
## 1 0.493        49.6      150. FALSE      49.6 
## 2 0.290        29.6      130. FALSE      29.6 
## 3 0.0764        7.77     108. FALSE       7.77
## 4 0.706        71.1      171. FALSE      71.1 
## 5 0.722        72.5      172. FALSE      72.5 
## 6 0.454        45.4      145. FALSE      45.4
```
]

--

.pull-right[


```r
df %&gt;% group_by(X) %&gt;% 
  summarize(Y = mean(Observed.Y)) %&gt;%
  pull(Y) %&gt;% diff
```

```
## [1] 150.035
```

* That's not the correct effect size!

* But if we properly model the assignment process and compare apples to apples?


```r
df %&gt;% filter(abs(Z-.9)&lt;.01) %&gt;% 
  group_by(X) %&gt;% 
  summarize(Y = mean(Observed.Y)) %&gt;%
  pull(Y) %&gt;% diff
```

```
## [1] 100.9051
```
]

---

# Building the Counterfactual

* In that last example our first attempt failed because we had not taken selection into account.

* It turns out that `Z` influences `Y.without.X`, which at the same time will be part of our estimator for the true effect size.

* But `Z` also determines who gets treatment! All the ones with `Z &gt; 0.9`!

* So, people with `Z &gt; 0.9` get treated, but **also** have a relatively high `Y.without.X`. 

* You can see that there is a depenence between the assignment and the effect size.


---

class: title-slide-final, middle

# Materials used to make these set of slides 

* Applied Econometrics: Causal Inference and Research Design, S. Cunningham, 2017

* Counterfactuals and Causal Inference, Methods and Principles for Social Research, S. L. Morgan, C. Winship, 2015

Thanks to the authors for making it available! 
---

class: title-slide-final, middle
background-image: url(../img/logo/ScPo-econ.png)
background-size: 250px
background-position: 9% 19%

# END




|                                                                                                            |                                   |
| :--------------------------------------------------------------------------------------------------------- | :-------------------------------- |
| &lt;a href="mailto:florian.oswald@sciencespo.fr"&gt;.ScPored[&lt;i class="fa fa-paper-plane fa-fw"&gt;&lt;/i&gt;]               | florian.oswald@sciencespo.fr       |
| &lt;a href="https://github.com/ScPoEcon/ScPoEconometrics-Slides"&gt;.ScPored[&lt;i class="fa fa-link fa-fw"&gt;&lt;/i&gt;] | Slides |
| &lt;a href="https://scpoecon.github.io/ScPoEconometrics"&gt;.ScPored[&lt;i class="fa fa-link fa-fw"&gt;&lt;/i&gt;] | Book |
| &lt;a href="http://twitter.com/ScPoEcon"&gt;.ScPored[&lt;i class="fa fa-twitter fa-fw"&gt;&lt;/i&gt;]                          | @ScPoEcon                         |
| &lt;a href="http://github.com/ScPoEcon"&gt;.ScPored[&lt;i class="fa fa-github fa-fw"&gt;&lt;/i&gt;]                          | @ScPoEcon                       |
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/remark/0.14.0/remark.min.js"></script>
<script src="../js/ru_xaringan.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
