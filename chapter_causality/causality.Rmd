---
title: "ScPoEconometrics"
subtitle: "Intro To Causality"
author: "Florian Oswald"
date: "SciencesPo Paris </br> `r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [default, "../css/scpo.css", "../css/scpo-fonts.css"]
    nature:
      beforeInit: ["../js/ru_xaringan.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
    includes:
      in_header: "../libs/partials/header.html"
---

layout: true

<div class="my-footer"><img src="../img/logo/ScPo-shield.png" style="height: 60px;"/></div> 

---

```{r setup, include=FALSE,warning=FALSE,message=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  dev = "svg",
  cache = TRUE,
  fig.align = "center"
  #fig.width = 11,
  #fig.height = 5
)

# define vars
om = par("mar")
lowtop = c(om[1],om[2],0.1,om[4])

overwrite = FALSE

```

layout: true

<div class="my-footer"><img src="../img/logo/ScPo-shield.png" style="height: 60px;"/></div> 

---

# Packages used in this set of slides

```{r}
library(tidyverse)
```

---

# Why Causality?

- Many of the interesting questions we might want to answer with data are causal<sup>1</sup>

- Some are non-causal, too - for example, "how can we predict whether this photo is of a dog or a cat" is vital to how Google Images works, but it doesn't care what *caused* the photo to be of a dog or a cat

- Nearly every *why* question is causal

- *Why* is a first order question for any policy maker thinking about a new policy.

.footnote[
[1]: This set of slides follows closely the great material by [Nick Huntington Klein](https://nickch-k.github.io/introcausality/)
]

---

# Also

- This is economists' comparative advantage!

- Plenty of fields do statistics. But very few make it standard training for their students to understand causality

- This understanding of causality makes economists very useful! *This* is one big reason why tech companies have whole economics departments in them

---

# So what is causality?

- We say that `X` *causes* `Y` if...

- were we to intervene and *change* the value of `X` without changing anything else...

- then `Y` would also change as a result

---

# Some examples of causal relationships

.pull-left[
## Some Obvious:

- A light switch being set to on causes the light to be on

- Setting off fireworks raises the noise level

]

--

.pull-right[

## Some less obvious:

- Getting a college degree increases your earnings

- Tariffs reduce the amount of trade

]

---

# Correlation vs Causation

* That's becomes almost a trueism: *Correlation is not equal Causation*.

* Well, we're here to figure out conditions when it **is**!

## Examples of non-zero *correlations* that are not *causal* (or may be causal in the wrong direction!)

.pull-left[

### Some obvious:

- People tend to wear shorts on days when ice cream trucks are out

- Rooster crowing sounds are followed closely by sunrise

] 

.pull-right[

### Some less obvious:

- Colds tend to clear up a few days after you take Emergen-C

- The performance of the economy tends to be lower or higher depending on the president's political party

]

---

# [Spurious](https://www.tylervigen.com/spurious-correlations) Correlation?

![](../img/photos/spurious.png)

---

# Good and Bad Correlation?

* *Correlation* is a well-defined concept of statistical **association**

* It's clearly true that space launches and Sociology doctorates have a correlation coefficient of 78%.

* However, what relationship lies **behind** this association is a more difficult question. 

* In other words, what does it **mean** to measure a correlation between two variables?

---


# Important Note

- "X causes Y" *doesn't* mean that X is necessarily the *only* thing that causes Y

- And it *doesn't* mean that all Y must be X

- For example, using a light switch causes the light to go on

- But not if the bulb is burned out (no Y, despite X), or if the light was already on (Y without X)

- But still we'd say that using the switch causes the light! The important thing is that X *changes the probability* that Y happens, not that it necessarily makes it happen for certain


---

# So How Can We Tell?

- As just shown, there are plenty of *correlations* that aren't *causal*

- So if we have a correlation, how can we tell if it *is*?

- For this we're going to have to think hard about *causal inference*. That is, inferring causality from data.

---
layout: false
class: title-slide-section-red, middle

# Causal Inference



---
layout: true

<div class="my-footer"><img src="../img/logo/ScPo-shield.png" style="height: 60px;"/></div> 

---

# The Problem of Causal Inference

.pull-left[
- Let's try to think about whether some `X` causes `Y`

- That is, if we manipulated `X`, then `Y` would change as a result

- For simplicity, let's assume that `X` is either 1 or 0, like "got a medical treatment" or "didn't"

]

--

.pull-right[

## The Problem of Causal Inference

- Now, how can we know *what would happen* if we manipulated `X`?

- Let's consider just one person - Angela. We could just check what Angela's `Y` is when we make `X=0`, and then check what Angela's `Y` is again when we make `X=1`.

- Are those two `Y`s different? If so, `X` causes `Y`!

- Do that same process for everyone in your sample and you know in general what the effect of `X` on `Y` is.

]

---

# The Problem of Causal Inference


- You may have spotted the problem!

- Just like you can't be in two places at once, Angela can't exist both with `X=0` and with `X=1`. She either got that medical treatment or she didn't.

- Let's say she did. So for Angela, `X=1` and, let's say, her outcome is `Y=10`.

- The other one, what `Y` *would have been* if we made `X=0`, is **missing**. 

- We don't know what it is! Could also be `Y=10`. Could be `Y=9`. Could be `Y=1000`!


---


# The Problem of Causal Inference

- Well, why don't we just take someone who actually DOES have `X=0` and compare their `Y`?

- Because there are lots of reasons their `Y` could be different BESIDES `X`.

- They're not Angela! A character flaw to be sure. `r emo::ji("grinning")`

- So if we find someone, Gareth, with `X=0` and they have `Y=9`, is that because `X` increases `Y`, or is that just because Angela and Gareth would have had different `Y`s anyway?

- `r emo::ji("thinking")`

---


# The Problem of Causal Inference

- The main goal we have in doing causal inference is in making *as good a guess as possible* as to what that `Y` *would have been* if `X` had been different.

- That "would have been" is called a *counterfactual* - counter to the fact of what actually happened.

- In doing so, we want to think about two people/firms/countries that are basically *exactly the same* except that one has `X=0` and one has `X=1`.

- If we could, we'd pick someone *identical* to Angela, the only difference being that they had `X=0` and not `X=1`.





---
layout: false
class: title-slide-section-red, middle

# Experiments



---
layout: true

<div class="my-footer"><img src="../img/logo/ScPo-shield.png" style="height: 60px;"/></div> 

---

# Experiments

.pull-left[
- A common way to do this in many fields is an *experiment*.

- If you can *randomly assign* `X`, then you know that the people with `X=0` are, on average, exactly the same as the people with `X=1`.

<<<<<<< HEAD
Last week we regressed average student math and reading scores on class size.
||||||| merged common ancestors
Last week we regressed class size on average student math and reading scores.
=======
- So that's an easy comparison!
>>>>>>> 996b8c7cc9eb0bfdd71ffe225c35208855af45d9

]

--

.pull-right[


- When we're working with people/firms/countries, running experiments is often infeasible, impossible, or unethical.

- So we have to think hard about a *model* of what the world looks like.

- So that we can use our model to figure out what the *counterfactual* would be.

]


---

# Models

- In causal inference, the *model* is our idea of what we think the process is that *generated the data*.

- We have to make some assumptions about what this is!

- We put together what we know about the world with assumptions and end up with our model.

- The model can then tell us what kinds of things could give us wrong results so we can fix them and get the right counterfactual.

---

# Models

- Wouldn't it be nice to not have to make assumptions?

- Yeah, but it's impossible to skip!

- We're trying to predict something that hasn't happened - a counterfactual.

- This is literally impossible to do if you don't have some model of how the data is generated.

<<<<<<< HEAD
1. Keep only cases with no `NA`s with the following code:  
`star_df <- star_df[complete.cases(star_df),]`
||||||| merged common ancestors
1. Keep only cases with no `NA`s with the following code:  
`star_df <- star_df[complete.cases(star_long),]`
=======
- You can't even predict the sun will rise tomorrow without a model!
>>>>>>> 996b8c7cc9eb0bfdd71ffe225c35208855af45d9

- If you think you can, you're just don't realize the model you're using - that's dangerous!

---

# An Example: Randomization

- Let's generate some data.
- Let's say that getting `X` causes `Y` to increase by 100.
- And let's run a randomized experiment of who actually gets X and estimate the size of the effect (should be close to `100`!)

.pull-left[
```{r, echo=TRUE, eval=TRUE}
true_effect <- 100
df <- tibble(Y.without.X = rnorm(1000),
             X=sample(c(0,1),1000,replace=T)) %>%
  mutate(Y.with.X = Y.without.X + true_effect) %>%
  #Now assign who actually gets X
  mutate(Observed.Y = ifelse(X==1,Y.with.X,Y.without.X))
head(df,4)
```
]

.pull-right[
* Now, estimate the group means and simply difference them:
```{r}
#And see what effect our experiment suggests X has on Y
df %>% group_by(X) %>% 
  summarize(Y = mean(Observed.Y)) %>%
  pull(Y) %>% diff
```
]

* That's pretty close to the true effect there!

---

# An Example: No Randomization

- Suppose now we can *not* randomize the `X`.

- Instead there is some kind of rule that decides about `X`.

.pull-left[
```{r, echo=TRUE, eval=TRUE}
df <- tibble(Z = runif(10000)) %>% 
  mutate(Y.without.X = rnorm(10000)+100*Z, 
         Y.with.X = Y.without.X + 100) %>%
  #Now assign who actually gets X
  mutate(X = Z > .9,
         Observed.Y = ifelse(X==1,Y.with.X,Y.without.X))
head(df)
```
]

--

.pull-right[

```{r}
df %>% group_by(X) %>% 
  summarize(Y = mean(Observed.Y)) %>%
  pull(Y) %>% diff
```

* That's not the correct effect size!

<<<<<<< HEAD
# The Project STAR Experiment: Regression

From the estimation output we get the following:

$\begin{align} \mathbb{E}[\textrm{math score} | D_i = 0]&= \mathbb{E}[b_0 + \delta D_i + e_i | D_i = 0] \\ &= b_0 + \delta \mathbb{E}[D_i| D_i = 0] + \mathbb{E}[e_i|D_i = 0] \\ &= b_0 \end{align}$

--
||||||| merged common ancestors
# The Project STAR Experiment: Regression

From the estimation output we get the following:

$\begin{align} \mathbb{E}[\textrm{math score} | D_i = 0]&= \mathbb{E}[b_0 + \delta D_i + e_i | D_i = 0] \\ &= b_0 + \delta \mathbb{E}[D_i| D_i = 0] \\ &= b_0 \end{align}$

--
=======
* But if we properly model the assignment process and compare apples to apples?
>>>>>>> 996b8c7cc9eb0bfdd71ffe225c35208855af45d9

<<<<<<< HEAD
$\begin{align} \mathbb{E}[\textrm{math score} | D_i = 1]&= \mathbb{E}[b_0 + \delta D_i + e_i | D_i = 1] \\ &= b_0 + \delta \mathbb{E}[D_i| D_i = 1] + \mathbb{E}[e_i|D_i = 1] \\ &= b_0 + \delta \end{align}$

--

$\begin{align} ATE &= \mathbb{E}[\textrm{math score} | D_i = 1] - \mathbb{E}[\textrm{math score} | D_i = 0] \\ &= b_0 + \delta - b_0 \\ &= \delta \end{align}$

--

We knew this already but we now understand why this is true `r emo::ji("v")`

---

class:inverse

# Task 4 (10 minutes)

1. Filter the dataset to only keep first graders and the small class and regular class groups.

1. Compute the average math score for both groups, and the difference between the two. (Use base `R`.)

1. Create a dummy variable `treatment` equal to `TRUE` if student is in treatment group (i.e. small class size) and `FALSE` if in control group (i.e. regular class size). See slide 33 for how to create a dummy variable.

1. Regress math score on the treatment dummy variable. Are the results in line with the previous question?

1. How do you interpret these coefficients?
||||||| merged common ancestors
$\begin{align} \mathbb{E}[\textrm{math score} | D_i = 1]&= \mathbb{E}[b_0 + \delta D_i + e_i | D_i = 1] \\ &= b_0 + \delta \mathbb{E}[D_i| D_i = 1] \\ &= b_0 + \delta \end{align}$

--

$\begin{align} ATE &= \mathbb{E}[\textrm{math score} | D_i = 1] - \mathbb{E}[\textrm{math score} | D_i = 0] \\ &= b_0 + \delta - b_0 \\ &= \delta \end{align}$

--

We knew this already but we now understand why this is true `r emo::ji("v")`

---

class:inverse

# Task 4 (10 minutes)

1. Filter the dataset to only keep first graders and the small class and regular class groups.

1. Compute the average math score for both groups, and the difference between the two. (Use base `R`.)

1. Create a dummy variable `treatment` equal to `TRUE` if student is in treatment group (i.e. small class size) and `FALSE` if in control group (i.e. regular class size). See slide 33 for how to create a dummy variable.

1. Regress the treatment dummy variable on math score. Are the results in line with the previous question?

1. How do you interpret these coefficients?
=======
```{r}
df %>% filter(abs(Z-.9)<.01) %>% 
  group_by(X) %>% 
  summarize(Y = mean(Observed.Y)) %>%
  pull(Y) %>% diff
```
]
>>>>>>> 996b8c7cc9eb0bfdd71ffe225c35208855af45d9

---

# Building the Counterfactual

* In that last example our first attempt failed because we had not taken selection into account.

* It turns out that `Z` influences `Y.without.X`, which at the same time will be part of our estimator for the true effect size.

* But `Z` also determines who gets treatment! All the ones with `Z > 0.9`!

* So, people with `Z > 0.9` get treated, but **also** have a relatively high `Y.without.X`. 

* You can see that there is a depenence between the assignment and the effect size.


---

class: title-slide-final, middle

# THANKS

To [Nick Huntington Klein](http://www.nickchk.com/index.html) for making his lecture material available online!

---

class: title-slide-final, middle
background-image: url(../img/logo/ScPo-econ.png)
background-size: 250px
background-position: 9% 19%

# END




|                                                                                                            |                                   |
| :--------------------------------------------------------------------------------------------------------- | :-------------------------------- |
| <a href="mailto:florian.oswald@sciencespo.fr">.ScPored[<i class="fa fa-paper-plane fa-fw"></i>]               | florian.oswald@sciencespo.fr       |
| <a href="https://github.com/ScPoEcon/ScPoEconometrics-Slides">.ScPored[<i class="fa fa-link fa-fw"></i>] | Slides |
| <a href="https://scpoecon.github.io/ScPoEconometrics">.ScPored[<i class="fa fa-link fa-fw"></i>] | Book |
| <a href="http://twitter.com/ScPoEcon">.ScPored[<i class="fa fa-twitter fa-fw"></i>]                          | @ScPoEcon                         |
| <a href="http://github.com/ScPoEcon">.ScPored[<i class="fa fa-github fa-fw"></i>]                          | @ScPoEcon                       |

